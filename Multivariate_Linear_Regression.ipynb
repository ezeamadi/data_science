{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gradient Descent is the process of minimizing a function following the \n",
    "#  slope or gradient of that function. We can use a technique that \n",
    "#  evaluates and updates the coefficients every iteration called \n",
    "#  stochastic gradient descent to minimize the error of a model on our \n",
    "#  training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed, randrange\n",
    "from csv import reader\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a CSV file\n",
    "\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string column to float\n",
    "\n",
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the min and max values for each column\n",
    "\n",
    "def dataset_minmax(dataset):\n",
    "    minmax = list()\n",
    "    for i in range(len(dataset[0])):\n",
    "        col_values = [row[i] for row in dataset]\n",
    "        value_min = min(col_values)\n",
    "        value_max = max(col_values)\n",
    "        minmax.append([value_min, value_max])\n",
    "    return minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale dataset columns to the range 0-1\n",
    "\n",
    "def normalize_dataset(dataset, minmax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(row)):\n",
    "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a dataset into k folds\n",
    "\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for _ in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate root mean squared error\n",
    "\n",
    "def rmse_metric(actual, predicted):\n",
    "    sum_error = 0.0\n",
    "    for i in range(len(actual)):\n",
    "        prediction_error = predicted[i] - actual[i]\n",
    "        sum_error += (prediction_error ** 2)\n",
    "    mean_error = sum_error / float(len(actual))\n",
    "    return sqrt(mean_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate an algorithm using a cross validation split\n",
    "\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        rmse = rmse_metric(actual, predicted)\n",
    "        scores.append(rmse)\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Coefficients\n",
    "\n",
    "def predict(row, coefficients):\n",
    "    yhat = coefficients[0]\n",
    "    for i in range(len(row) - 1):\n",
    "        yhat += coefficients[i + 1] * row[i]\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gradient Descent\n",
    "\n",
    "def coefficients_sgd(train, l_rate, n_epoch):\n",
    "    coef = [0.0 for i in range(len(train[0]))]\n",
    "    for epoch in range(n_epoch):\n",
    "        sum_error = 0\n",
    "        for row in train:\n",
    "            yhat = predict(row, coef)\n",
    "            error = yhat - row[-1]\n",
    "            sum_error += error**2\n",
    "            coef[0] = coef[0] - l_rate * error\n",
    "            \n",
    "            for i in range(len(row) - 1):\n",
    "                coef[i+1] = coef[i+1] - l_rate * error * row[i]\n",
    "\n",
    "    return coef\n",
    "\n",
    "# Modify this later to Change the stochastic gradient descent algorithm to\n",
    "# accumulate updates across each epoch and only update the coefficients in\n",
    "# a batch at the end of the epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def coefficients_sgd(train, l_rate, n_epoch):\n",
    "#     coef = [0.0 for i in range(len(train[0]))]\n",
    "#     for epoch in range(n_epoch):\n",
    "#         sum_error = 0\n",
    "#         for row in train:\n",
    "#             yhat = predict(row, coef)\n",
    "#             error = yhat - row[-1]\n",
    "#             sum_error += error**2\n",
    "        \n",
    "#         coef[0] = coef[0] - l_rate * error\n",
    "#         for i in range(len(row) - 1):\n",
    "#             coef[i+1] = coef[i+1] - l_rate * error * row[i]\n",
    "\n",
    "#     return coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Algorithm With Stochastic Gradient Descent\n",
    "\n",
    "def linear_regression_sgd(train, test, l_rate, n_epoch):\n",
    "    predictions = list()\n",
    "    coef = coefficients_sgd(train, l_rate, n_epoch)\n",
    "    for row in test:\n",
    "        yhat = predict(row, coef)\n",
    "        predictions.append(yhat)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.4318709951784056, 0.42194355828810504, 0.42001100130264185, 0.41489738052734504, 0.4249896614511914, 0.420170483912735, 0.4241943606916924, 0.4162484038875378, 0.4164514673343109, 0.40010221378062283]\n",
      "Mean RMSE: 0.419\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "\n",
    "filename = 'winequality-white.csv'\n",
    "dataset = load_csv(filename)\n",
    "\n",
    "for i in range(len(dataset[0])):\n",
    "    str_column_to_float(dataset, i)\n",
    "\n",
    "# Normalize\n",
    "minmax = dataset_minmax(dataset)\n",
    "normalize_dataset(dataset, minmax)\n",
    "\n",
    "# Evaluate Algorithm\n",
    "n_folds = 10\n",
    "l_rate = 0.001\n",
    "n_epoch = 100\n",
    "\n",
    "scores = evaluate_algorithm(dataset, \n",
    "                            linear_regression_sgd, \n",
    "                            n_folds, l_rate, n_epoch\n",
    "                           )\n",
    "\n",
    "print(\"Scores: %s\" % scores)\n",
    "print(\"Mean RMSE: %.3f\" % (sum(scores) / float(len(scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.33262367822435085, 0.337809041849811, 0.34236855432005864, 0.32094959227669545, 0.32033134245694134, 0.3436898189998329, 0.31324020670977804, 0.3184755546765138, 0.3093821277804809, 0.35746993405645944]\n",
      "Mean RMSE: 0.330\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "\n",
    "filename = 'winequality-red.csv'\n",
    "dataset = load_csv(filename)\n",
    "\n",
    "for i in range(len(dataset[0])):\n",
    "    str_column_to_float(dataset, i)\n",
    "\n",
    "# Normalize\n",
    "minmax = dataset_minmax(dataset)\n",
    "normalize_dataset(dataset, minmax)\n",
    "\n",
    "# Evaluate Algorithm\n",
    "n_folds = 15\n",
    "l_rate = 0.001\n",
    "n_epoch = 100\n",
    "\n",
    "scores = evaluate_algorithm(dataset, \n",
    "                            linear_regression_sgd, \n",
    "                            n_folds, l_rate, n_epoch\n",
    "                           )\n",
    "\n",
    "print(\"Scores: %s\" % scores)\n",
    "print(\"Mean RMSE: %.3f\" % (sum(scores) / float(len(scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
