{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classification Accuracy\n",
    "\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test accuracy\n",
    "\n",
    "actual = [0,0,0,0,0,1,1,1,1,1]\n",
    "predicted = [0,1,0,0,0,1,0,1,1,1]\n",
    "accuracy = accuracy_metric(actual, predicted)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(actual, predicted):\n",
    "    unique = set(actual)\n",
    "    matrix = [list() for x in range(len(unique))]\n",
    "    \n",
    "    for i in range(len(unique)):\n",
    "        matrix[i] = [0 for x in range(len(unique))]\n",
    "    \n",
    "    lookup = dict()\n",
    "    for i, value in enumerate(unique):\n",
    "        lookup[value] = i\n",
    "    \n",
    "    for i in range(len(actual)):\n",
    "        x = lookup[actual[i]]\n",
    "        y = lookup[predicted[i]]\n",
    "        matrix[y][x] += 1\n",
    "        \n",
    "    return unique, matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test accuracy\n",
    "\n",
    "actual = [0,0,0,0,0,1,1,1,1,1]\n",
    "predicted = [0,1,1,0,0,1,0,1,1,1]\n",
    "\n",
    "confusion_matrix(actual, predicted)\n",
    "unique, matrix = confusion_matrix(actual, predicted)\n",
    "\n",
    "print(unique)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty print a confusion matrix\n",
    "\n",
    "def print_confusion_matrix(unique, matrix): \n",
    "    print('(A) ' + ' '.join(str(x) for x in unique)) \n",
    "    print('(P) ---')\n",
    "    for i, x in enumerate(unique):\n",
    "        print(\"%s|  %s \" % (x, ' '.join(str(x) for x in matrix[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_confusion_matrix(unique, matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean absolute error\n",
    "\n",
    "def mae_metric(actual, predicted):\n",
    "    sum_error = 0.0\n",
    "    for i in range(len(actual)):\n",
    "        sum_error += abs(predicted[i] - actual[i])\n",
    "    return sum_error / float(len(actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_metric(actual, predicted):\n",
    "    sum_error = 0.0\n",
    "    for i in range(len(actual)):\n",
    "        prediction_error = predicted[i] - actual[i]\n",
    "        sum_error += (prediction_error ** 2)\n",
    "    mean_error = sum_error / float(len(actual))\n",
    "    return sqrt(mean_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Validation Accuracies\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "dataset = 'pima-indians-diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', \n",
    "         'pedi', 'age', 'class']\n",
    "dataframe = pd.read_csv(dataset, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:, 0:8]\n",
    "Y = array[:, 8]\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=7, shuffle=True)\n",
    "model = LogisticRegression(solver='liblinear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.086 (0.051)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification Accuracy\n",
    "\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold, \n",
    "                                          scoring='accuracy')\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (results.mean()*100.0, results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logloss: -0.494 (0.042)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification LogLoss\n",
    "\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold, \n",
    "                                          scoring='neg_log_loss')\n",
    "print(\"Logloss: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.826 (0.050)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification ROC AUC\n",
    "\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold, \n",
    "                                          scoring=\"roc_auc\")\n",
    "print(\"AUC: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[141  21]\n",
      " [ 41  51]]\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification Confusion Matrix\n",
    "\n",
    "test_size = 0.33\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, \n",
    "                                                                    test_size=test_size, \n",
    "                                                                    random_state=7\n",
    "                                                                   )\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "matrix = confusion_matrix(Y_test, predicted)\n",
    "print(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.87      0.82       162\n",
      "         1.0       0.71      0.55      0.62        92\n",
      "\n",
      "    accuracy                           0.76       254\n",
      "   macro avg       0.74      0.71      0.72       254\n",
      "weighted avg       0.75      0.76      0.75       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification Report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(Y_test, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -3.387 (0.667)\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "##   Regression Metrics   ##\n",
    "############################\n",
    "\n",
    "\n",
    "# Cross Validation Regression MAE\n",
    "\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "dataset = 'housing.csv'\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
    "         'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "dataframe = pandas.read_csv(dataset, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:, 0:13]\n",
    "Y = array[:, 13]\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=7, shuffle=True)\n",
    "model = LinearRegression()\n",
    "\n",
    "scoring = 'neg_mean_absolute_error'\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold, \n",
    "                                          scoring=scoring)\n",
    "print(\"MAE: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: -23.747 (11.143)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Regression MSE\n",
    "\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold, \n",
    "                                          scoring=scoring\n",
    "                                         )\n",
    "print(\"MSE: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.718 (0.099)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Regression R^2\n",
    "\n",
    "scoring = 'r2'\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold, \n",
    "                                          scoring=scoring\n",
    "                                         )\n",
    "print(\"R^2: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
